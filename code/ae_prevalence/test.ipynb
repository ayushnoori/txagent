{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports and Script Configuration ---\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.progress import track\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "\n",
    "# Initialize pretty printing console\n",
    "console = Console()\n",
    "\n",
    "# --- Copied from your script ---\n",
    "CONFIGURATIONS = [\n",
    "    {\n",
    "        \"disease\": \"diabetes\",\n",
    "        \"comorbidity\": \"chronic kidney disease\",\n",
    "        \"drugs\": [\"dulaglutide\"],\n",
    "        \"aes\": [\"pancreatitis\", \"hypoglycemia\"],\n",
    "        \"enabled\": False,\n",
    "    },\n",
    "    {\n",
    "        \"disease\": \"hypertension\",\n",
    "        \"comorbidity\": \"chronic kidney disease\",\n",
    "        \"drugs\": [\"losartan\", \"valsartan\", \"irbesartan\", \"candesartan\", \"olmesartan\"],\n",
    "        \"drug_group_name\": \"ARB\",\n",
    "        \"aes\": [\"hyperkalemia\", \"systemic lupus erythematosus\"],\n",
    "        \"enabled\": False,\n",
    "    },\n",
    "    {\n",
    "        \"disease\": \"hypertension\",\n",
    "        \"comorbidity\": \"gout\",\n",
    "        \"drugs\": [\"atenolol\", \"metoprolol\", \"propranolol\", \"bisoprolol\", \"carvedilol\", \"labetalol\", \"timolol\", \"oxprenolol\", \"pindolol\"],\n",
    "        \"drug_group_name\": \"beta-blocker\",\n",
    "        \"aes\": [\"acute kidney failure\", \"unspecified acute kidney failure\", \"hyperkalemia\", \"cardiac dysrhythmia\"],\n",
    "        \"enabled\": True,\n",
    "    },\n",
    "    # ... other configurations from your script\n",
    "]\n",
    "\n",
    "# --- Global Paths & Settings ---\n",
    "ROOT_DIR = Path(\"//10.100.117.220/Research_Archive$/Archive/R01/R01-Ayush/\")\n",
    "RESULTS_DIR = ROOT_DIR / \"results\"\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "GROUPS_DIR = ROOT_DIR / \"code\" / \"groups\"\n",
    "WINDOWS = [30, 90, None]\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def slugify(text: str) -> str:\n",
    "    return \"\".join(ch.lower() if ch.isalnum() else '_' for ch in text).strip(\"_\")\n",
    "\n",
    "def clean_label(text: str) -> str:\n",
    "    return text.lower().replace(\"_\", \" \")\n",
    "\n",
    "def _read_clean_groups(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "    if \"exclude\" in df.columns:\n",
    "        df = df[df[\"exclude\"].str.lower() != 'true']\n",
    "    if \"name\" in df.columns:\n",
    "        df[\"name_key\"] = df[\"name\"].str.casefold()\n",
    "    return df\n",
    "\n",
    "def build_where_clause(rules: list) -> str:\n",
    "    parts = [f\"({tc} = '{tv}' AND {c} LIKE '{pat}')\" for c, tc, tv, pat in rules]\n",
    "    return \"(\" + \" OR \".join(parts) + \")\"\n",
    "\n",
    "# --- 2. Main Setup Execution ---\n",
    "console.print(Panel(\"[bold magenta]Adverse Event Analysis Setup for Jupyter[/bold magenta]\", subtitle=\"Loading data...\", expand=False))\n",
    "\n",
    "# Load shared definition files\n",
    "with console.status(\"[b]Loading shared definition files...[/b]\", spinner=\"dots\"):\n",
    "    group_files = {\n",
    "        \"base\": GROUPS_DIR / \"base.csv\",\n",
    "        \"comorbidity\": GROUPS_DIR / \"comorbidities.csv\",\n",
    "        \"drugs\": GROUPS_DIR / \"drugs.csv\",\n",
    "        \"ae\": GROUPS_DIR / \"adverse_effects.csv\",\n",
    "        \"confounders\": GROUPS_DIR / \"confounders.csv\"\n",
    "    }\n",
    "    group_dfs = {}\n",
    "    for name, path in group_files.items():\n",
    "        if path.exists():\n",
    "            group_dfs[name] = _read_clean_groups(path)\n",
    "        else:\n",
    "            if name == 'confounders':\n",
    "                console.print(\"[yellow]NOTE: 'confounders.csv' not found. Regression will only adjust for age.[/yellow]\")\n",
    "                group_dfs[name] = pd.DataFrame(columns=['name', 'name_key', 'col', 'type_col', 'type_val', 'like_pattern'])\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Essential definition file not found: {path}\")\n",
    "console.print(\"Shared definition files loaded.\")\n",
    "\n",
    "# Connect to database\n",
    "con = duckdb.connect(database=\":memory:\")\n",
    "console.print(\"In-memory DuckDB connection established.\")\n",
    "\n",
    "# Select the first enabled configuration to run the setup\n",
    "try:\n",
    "    config = next(c for c in CONFIGURATIONS if c.get(\"enabled\", True))\n",
    "except StopIteration:\n",
    "    raise ValueError(\"No enabled configuration found in the CONFIGURATIONS list.\")\n",
    "\n",
    "# --- Execute Steps 1-3 from process_configuration() ---\n",
    "\n",
    "# Display configuration info\n",
    "title = f\"Setting up for: {clean_label(config['disease'])} + {clean_label(config['comorbidity'])}\"\n",
    "content = Text(no_wrap=True)\n",
    "content.append(\"  Disease (D): \", style=\"green\"); content.append(f\"{clean_label(config['disease'])}\\n\")\n",
    "content.append(\"  Comorbidity (D2): \", style=\"green\"); content.append(f\"{clean_label(config['comorbidity'])}\\n\")\n",
    "if config.get(\"drug_group_name\"):\n",
    "    content.append(\"  Drug Group (C): \", style=\"green\"); content.append(f\"{config['drug_group_name']}\\n\")\n",
    "else:\n",
    "    content.append(\"  Drugs (C): \", style=\"green\"); content.append(f\"{', '.join(config['drugs'])}\\n\")\n",
    "content.append(\"  Adverse Events (E): \", style=\"green\"); content.append(f\"{', '.join(config['aes'])}\")\n",
    "console.print(Panel(content, title=title, border_style=\"cyan\", title_align=\"left\"))\n",
    "\n",
    "# Step 1: Load and Validate Selections\n",
    "console.print(Panel(\"Step 1: Load and Validate Selections\", title_align=\"left\", border_style=\"blue\"))\n",
    "disease, comorbidity, drugs, aes = config[\"disease\"], config[\"comorbidity\"], config[\"drugs\"], config[\"aes\"]\n",
    "sel_disease, sel_comorb = [disease.strip().casefold()], [comorbidity.strip().casefold()]\n",
    "sel_drugs, sel_aes = [d.strip().casefold() for d in drugs], [a.strip().casefold() for a in aes]\n",
    "\n",
    "def _rules_from(df, selected_names):\n",
    "    sub = df[df[\"name_key\"].isin(selected_names)].drop_duplicates()\n",
    "    return [(r.col, r.type_col, r.type_val, r.like_pattern) for r in sub.itertuples(index=False)]\n",
    "\n",
    "base_disease_rules = _rules_from(group_dfs[\"base\"], sel_disease)\n",
    "comorbidity_rules = _rules_from(group_dfs[\"comorbidity\"], sel_comorb)\n",
    "drug_codes = group_dfs[\"drugs\"][group_dfs[\"drugs\"][\"name_key\"].isin(sel_drugs)][\"atc5_code\"].dropna().unique().tolist()\n",
    "\n",
    "adverse_events = []\n",
    "for ae_name, grp in group_dfs[\"ae\"][group_dfs[\"ae\"][\"name_key\"].isin(sel_aes)].groupby(\"name_key\", sort=True):\n",
    "    rules = [(r.col, r.type_col, r.type_val, r.like_pattern) for r in grp.itertuples(index=False)]\n",
    "    adverse_events.append({\"name\": grp['name'].iloc[0], \"rules\": rules})\n",
    "\n",
    "confounders = []\n",
    "if \"confounders\" in group_dfs and not group_dfs[\"confounders\"].empty:\n",
    "    for conf_name, grp in group_dfs[\"confounders\"].groupby(\"name_key\", sort=True):\n",
    "        rules = [(r.col, r.type_col, r.type_val, r.like_pattern) for r in grp.itertuples(index=False)]\n",
    "        confounders.append({\"name\": grp['name'].iloc[0], \"rules\": rules})\n",
    "\n",
    "console.print(f\"  [green]Selections validated successfully.[/green]\")\n",
    "\n",
    "# Step 2: Set Up Database Views\n",
    "console.print(Panel(\"Step 2: Set Up Database Views\", title_align=\"left\", border_style=\"blue\"))\n",
    "cohort_dir = DATA_DIR / \"cohorts\" / disease\n",
    "pop_file = cohort_dir / f\"population_{disease}.parquet\"\n",
    "dx_file = cohort_dir / f\"diagnoses_{disease}.parquet\"\n",
    "med_file = cohort_dir / f\"meds_{disease}.parquet\"\n",
    "\n",
    "with console.status(\"[b]Creating database views from Parquet files...[/b]\", spinner=\"dots\"):\n",
    "    con.execute(f\"CREATE OR REPLACE VIEW dx AS SELECT patient_id, time_stamp::DATE AS diagnosis_date, TRIM(code1) AS code1, code_type1 FROM read_parquet('{dx_file.as_posix()}');\")\n",
    "    con.execute(f\"CREATE OR REPLACE VIEW meds AS SELECT patient_id, time_stamp::DATE AS rx_start_date, code1 AS atc5_code, type FROM read_parquet('{med_file.as_posix()}') WHERE type = 'Medications purchase';\")\n",
    "    latest_date = con.execute(\"SELECT MAX(diagnosis_date) FROM dx;\").fetchone()[0]\n",
    "    admin_end_date = latest_date.strftime('%Y-%m-%d')\n",
    "    # con.execute(f\"CREATE OR REPLACE VIEW pop AS SELECT patient_id, date_of_birth::DATE AS birth_date, COALESCE(date_of_death::DATE, DATE '{admin_end_date}') AS observation_end_date FROM read_parquet('{pop_file.as_posix()}');\")\n",
    "    \n",
    "    # Load population data into a Pandas DataFrame for imputation\n",
    "    pop_df = pd.read_parquet(pop_file)\n",
    "    \n",
    "    # --- Imputation of and categorization of socioeconomic_status ---\n",
    "    console.print(\"  [yellow]Categorizing and imputing socioeconomic_status...[/yellow]\")\n",
    "    n_missing_before = pop_df['socioeconomic_status'].isna().sum()\n",
    "\n",
    "    # Create categorical SES levels based on population tertiles (~33% each).\n",
    "    # NaNs in the original column will result in NaNs here.\n",
    "    ses_cats = pd.qcut(\n",
    "        pop_df['socioeconomic_status'],\n",
    "        q=3,\n",
    "        labels=['low', 'intermediate', 'high'],\n",
    "        duplicates='drop'  # Handles non-unique bin edges\n",
    "    )\n",
    "\n",
    "    # Impute missing SES values by assigning them to the 'intermediate' category.\n",
    "    # We use .astype('object') to allow filling with a string not in the original categories.\n",
    "    pop_df['socioeconomic_status'] = ses_cats.astype('object').fillna('intermediate')\n",
    "\n",
    "    # Ensure the column has a consistent categorical type for statsmodels\n",
    "    ses_order = ['low', 'intermediate', 'high']\n",
    "    pop_df['socioeconomic_status'] = pop_df['socioeconomic_status'].astype(pd.CategoricalDtype(categories=ses_order, ordered=True))\n",
    "    \n",
    "    n_imputed = n_missing_before\n",
    "    console.print(f\"  [green]Categorized SES into 3 levels and imputed {n_imputed:,} missing values to 'intermediate'.[/green]\")\n",
    "\n",
    "    # Define observation end date for the view\n",
    "    pop_df['observation_end_date'] = pd.to_datetime(pop_df['date_of_death']).fillna(pd.to_datetime(admin_end_date))\n",
    "    \n",
    "    # Register the imputed Pandas DataFrame as a temporary DuckDB table\n",
    "    con.register('pop_imputed', pop_df)\n",
    "    \n",
    "    # Create the final 'pop' view, now including sex and the imputed socioeconomic_status\n",
    "    con.execute(\"\"\"\n",
    "        CREATE OR REPLACE VIEW pop AS \n",
    "        SELECT \n",
    "            patient_id, \n",
    "            date_of_birth::DATE AS birth_date,\n",
    "            observation_end_date::DATE AS observation_end_date,\n",
    "            sex,\n",
    "            socioeconomic_status\n",
    "        FROM pop_imputed;\n",
    "    \"\"\")\n",
    "\n",
    "cohort_size = con.execute('SELECT COUNT(*) FROM pop;').fetchone()[0]\n",
    "console.print(f\"  [green]Overall cohort size for '{disease}':[/green] {cohort_size:,}\")\n",
    "\n",
    "# --- Demographic Summary ---\n",
    "console.print(Panel(\"Demographic Summary of Population\", title_align=\"left\", border_style=\"blue\"))\n",
    "\n",
    "sex_counts = pop_df['sex'].value_counts()\n",
    "ses_counts = pop_df['socioeconomic_status'].value_counts()\n",
    "\n",
    "demographics_table = Table(title=f\"Population Demographics for '{clean_label(disease)}'\")\n",
    "demographics_table.add_column(\"Statistic\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "demographics_table.add_column(\"Value\", justify=\"left\", style=\"magenta\")\n",
    "\n",
    "demographics_table.add_row(\"Total Patients\", f\"{len(pop_df):,}\")\n",
    "if 'F' in sex_counts:\n",
    "    demographics_table.add_row(\"Females\", f\"{sex_counts['F']:,} ({sex_counts['F']/len(pop_df)*100:.1f}%)\")\n",
    "if 'M' in sex_counts:\n",
    "    demographics_table.add_row(\"Males\", f\"{sex_counts['M']:,} ({sex_counts['M']/len(pop_df)*100:.1f}%)\")\n",
    "\n",
    "demographics_table.add_section()\n",
    "demographics_table.add_row(\"[bold]SES Category[/bold]\", \"\")\n",
    "if 'low' in ses_counts:\n",
    "    demographics_table.add_row(\"  Low\", f\"{ses_counts['low']:,} ({ses_counts['low']/len(pop_df)*100:.1f}%)\")\n",
    "if 'intermediate' in ses_counts:\n",
    "    demographics_table.add_row(\"  Intermediate\", f\"{ses_counts['intermediate']:,} ({ses_counts['intermediate']/len(pop_df)*100:.1f}%)\")\n",
    "if 'high' in ses_counts:\n",
    "    demographics_table.add_row(\"  High\", f\"{ses_counts['high']:,} ({ses_counts['high']/len(pop_df)*100:.1f}%)\")\n",
    "    \n",
    "console.print(demographics_table)\n",
    "\n",
    "# Step 3: Compute Index Dates and Define Cohorts\n",
    "console.print(Panel(\"Step 3: Compute Index Dates and Define Cohorts\", title_align=\"left\", border_style=\"blue\"))\n",
    "with console.status(\"[b]Identifying first diagnosis/drug dates...[/b]\", spinner=\"dots\"):\n",
    "    con.execute(f\"CREATE OR REPLACE TEMP TABLE base_disease AS SELECT patient_id, MIN(diagnosis_date) AS base_date FROM dx WHERE {build_where_clause(base_disease_rules)} GROUP BY patient_id;\")\n",
    "    con.execute(f\"CREATE OR REPLACE TEMP TABLE comorbidity AS SELECT patient_id, MIN(diagnosis_date) AS comorb_date FROM dx WHERE {build_where_clause(comorbidity_rules)} GROUP BY patient_id;\")\n",
    "    con.execute(f\"CREATE OR REPLACE TEMP TABLE drug_exposure AS SELECT patient_id, MIN(rx_start_date) AS drug_date FROM meds WHERE atc5_code IN {tuple(drug_codes)} GROUP BY patient_id;\")\n",
    "\n",
    "with console.status(\"[b]Building master patient flag table...[/b]\", spinner=\"dots\"):\n",
    "    con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TEMP TABLE patient_flags AS\n",
    "    SELECT p.patient_id,\n",
    "        CASE WHEN bd.base_date IS NOT NULL THEN 1 ELSE 0 END AS base_disease, bd.base_date,\n",
    "        CASE WHEN cd.comorb_date IS NOT NULL THEN 1 ELSE 0 END AS comorbidity, cd.comorb_date,\n",
    "        CASE WHEN de.drug_date IS NOT NULL THEN 1 ELSE 0 END AS drug, de.drug_date\n",
    "    FROM pop p\n",
    "    LEFT JOIN base_disease bd USING (patient_id) LEFT JOIN comorbidity cd USING (patient_id) LEFT JOIN drug_exposure de USING (patient_id);\n",
    "    \"\"\")\n",
    "\n",
    "with console.status(\"[b]Calculating cohort sizes...[/b]\", spinner=\"dots\"):\n",
    "    n_d, n_d2, n_c, n_d_d2, n_d_d2_c = con.execute(\"\"\"\n",
    "        SELECT SUM(base_disease), SUM(comorbidity), SUM(drug),\n",
    "               SUM(CASE WHEN base_disease = 1 AND comorbidity = 1 THEN 1 ELSE 0 END),\n",
    "               SUM(CASE WHEN base_disease = 1 AND comorbidity = 1 AND drug = 1 THEN 1 ELSE 0 END)\n",
    "        FROM patient_flags;\n",
    "    \"\"\").fetchone()\n",
    "\n",
    "table = Table(title=\"Cohort Sizes\")\n",
    "table.add_column(\"Cohort Definition\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "table.add_column(\"Patient Count\", justify=\"right\", style=\"magenta\")\n",
    "table.add_row(\"N(D)\", f\"{n_d:,}\")\n",
    "table.add_row(\"N(D2)\", f\"{n_d2:,}\")\n",
    "table.add_row(\"N(C)\", f\"{n_c:,}\")\n",
    "table.add_row(\"N(D + D2)\", f\"{n_d_d2:,}\")\n",
    "table.add_row(\"N(D + D2 + C)\", f\"{n_d_d2_c:,}\")\n",
    "console.print(table)\n",
    "\n",
    "# --- 4. Expose Variables for Testing ---\n",
    "console.print(\"\\n[bold magenta]SETUP COMPLETE.[/bold magenta] The following variables are now available for testing in subsequent cells:\")\n",
    "console.print(f\"- `con`: The DuckDB connection object containing `pop`, `dx`, `meds`, and `patient_flags`.\")\n",
    "console.print(f\"- `config`: The configuration dictionary for the current analysis.\")\n",
    "console.print(f\"- `adverse_events`: A list of adverse event definition dictionaries.\")\n",
    "console.print(f\"- `confounders`: A list of confounder definition dictionaries.\")\n",
    "console.print(f\"- `WINDOWS`: The list of time windows: {WINDOWS}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TEMP TABLE regression_base AS\n",
    "(SELECT patient_id, 1 AS exposed, drug_date AS index_date FROM patient_flags WHERE base_disease = 1 AND comorbidity = 1 AND drug = 1)\n",
    "UNION ALL\n",
    "(SELECT patient_id, 0 AS exposed, GREATEST(base_date, comorb_date) AS index_date FROM patient_flags WHERE base_disease = 1 AND comorbidity = 1 AND drug = 0);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TEMP TABLE regression_data AS\n",
    "SELECT\n",
    "    r.patient_id,\n",
    "    r.exposed,\n",
    "    r.index_date,\n",
    "    p.sex,\n",
    "    p.socioeconomic_status,\n",
    "    DATE_DIFF('year', p.birth_date, r.index_date) AS age_at_index\n",
    "FROM regression_base r\n",
    "JOIN pop p ON r.patient_id = p.patient_id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = con.execute(\"SELECT * FROM regression_data;\").fetchdf()\n",
    "\n",
    "# if model_df.empty:\n",
    "#     console.print(\"  [bold yellow]WARNING:[/] Base data for regression is empty. Skipping analysis.\")\n",
    "#     return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2638858",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "# 4. Iterate through each AE and run the regression model.\n",
    "for ae in track(adverse_events, description=\"Running regression models for AEs...\"):\n",
    "    ae_name, ae_slug = ae[\"name\"], slugify(ae[\"name\"])\n",
    "    ae_where = build_where_clause(ae[\"rules\"])\n",
    "    \n",
    "    ae_dates_df = con.execute(f\"SELECT patient_id, MIN(diagnosis_date) AS ae_date FROM dx WHERE {ae_where} GROUP BY patient_id;\").fetchdf()\n",
    "    \n",
    "    merged_df = pd.merge(model_df, ae_dates_df, on='patient_id', how='left')\n",
    "    merged_df['index_date'] = pd.to_datetime(merged_df['index_date'])\n",
    "    merged_df['ae_date'] = pd.to_datetime(merged_df['ae_date'])\n",
    "\n",
    "    for W in [None]: # WINDOWS:\n",
    "        win_label = \"any_after_index\" if W is None else f\"{W}d\"\n",
    "        console.print(f\"Processing model for: ([bold cyan]{clean_label(ae_name)}[/bold cyan], [yellow]{win_label}[/yellow])\")\n",
    "        \n",
    "        temp_df = merged_df.copy()\n",
    "        \n",
    "        if W is None:\n",
    "            temp_df['outcome'] = ((temp_df['ae_date'] > temp_df['index_date'])).astype(int)\n",
    "        else:\n",
    "            window_days = pd.to_timedelta(W, unit='d')\n",
    "            temp_df['outcome'] = ((temp_df['ae_date'] > temp_df['index_date']) & (temp_df['ae_date'] <= temp_df['index_date'] + window_days)).astype(int)\n",
    "\n",
    "        if temp_df['outcome'].sum() < 5: # Min events needed for a stable model\n",
    "            continue\n",
    "\n",
    "        # 5. Build the formula and fit the logistic regression model.\n",
    "        additional_confounders_str = \"\"\n",
    "        formula = f\"outcome ~ exposed + age_at_index + C(sex) + C(socioeconomic_status){additional_confounders_str}\"\n",
    "        \n",
    "        try:\n",
    "            model_vars = ['outcome', 'exposed', 'age_at_index', 'sex', 'socioeconomic_status']\n",
    "            temp_df.dropna(subset=model_vars, inplace=True)\n",
    "\n",
    "            model = smf.logit(formula, data=temp_df).fit(maxiter=100, disp=1)\n",
    "            \n",
    "            params = model.params\n",
    "            conf = model.conf_int()\n",
    "            pvalues = model.pvalues\n",
    "            \n",
    "            adj_or = np.exp(params.get('exposed', np.nan))\n",
    "            ci_low = np.exp(conf.loc['exposed', 0])\n",
    "            ci_high = np.exp(conf.loc['exposed', 1])\n",
    "            p_value = pvalues.get('exposed', np.nan)\n",
    "            \n",
    "            all_results.append({\n",
    "                \"adverse_event\": clean_label(ae_name),\n",
    "                \"window\": win_label,\n",
    "                \"adjusted_odds_ratio\": adj_or,\n",
    "                \"ci95_low\": ci_low,\n",
    "                \"ci95_high\": ci_high,\n",
    "                \"p_value\": p_value,\n",
    "                \"formula\": formula\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            console.print(f\"  [bold red]ERROR:[/] Could not fit regression for '{ae_name}' ({win_label}). Reason: {e}\")\n",
    "\n",
    "# return pd.DataFrame(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
