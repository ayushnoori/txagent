{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aaf74d9",
   "metadata": {},
   "source": [
    "# Test Notebook for AE Prevalence Analysis\n",
    "\n",
    "This notebook allows you to:\n",
    "1. Select a configuration from `configurations.py`\n",
    "2. Run all steps from `ae_prevalence.py` interactively\n",
    "3. Inspect intermediate outputs\n",
    "4. Test different code options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports and Setup ---\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "# To fix \"Tcl_AsyncDelete: async handler deleted by the wrong thread\" error.\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.progress import track, Progress, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn, MofNCompleteColumn\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "\n",
    "from configurations import CONFIGURATIONS\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "# Initialize pretty printing console\n",
    "console = Console()\n",
    "\n",
    "# --- Global Paths & Settings ---\n",
    "ROOT_DIR = Path(\"//10.100.117.220/Research_Archive$/Archive/R01/R01-Ayush/txagent/\")\n",
    "RESULTS_DIR = ROOT_DIR / \"results\"\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "GROUPS_DIR = ROOT_DIR / \"code\" / \"groups\"\n",
    "WINDOWS = [30, 90, 365, 1825, None]\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def slugify(text: str) -> str:\n",
    "    \"\"\"Converts text to a URL-friendly slug.\"\"\"\n",
    "    return \"\".join(ch.lower() if ch.isalnum() else '_' for ch in text).strip(\"_\")\n",
    "\n",
    "def clean_label(text: str) -> str:\n",
    "    \"\"\"Cleans a configuration string for display by lowercasing and replacing underscores.\"\"\"\n",
    "    return text.lower().replace(\"_\", \" \")\n",
    "\n",
    "def _read_clean_groups(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads and cleans a group definition CSV.\n",
    "    It also filters out any rows where the 'exclude' column is set to True.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if df.empty:\n",
    "            console.print(f\"  [yellow]WARNING:[/] Definition file is empty: {path.name}\")\n",
    "            return pd.DataFrame()\n",
    "    except pd.errors.EmptyDataError:\n",
    "        console.print(f\"  [yellow]WARNING:[/] Could not parse columns from file (it may be empty): {path.name}\")\n",
    "        return pd.DataFrame()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    # Standardize all columns to stripped strings for consistent processing\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "    # If an 'exclude' column exists, drop rows where its value is 'True' (case-insensitive)\n",
    "    if \"exclude\" in df.columns:\n",
    "        df = df[df[\"exclude\"].str.lower() != 'true']\n",
    "\n",
    "    if \"name\" in df.columns:\n",
    "        df[\"name_key\"] = df[\"name\"].str.casefold()\n",
    "        \n",
    "    return df\n",
    "\n",
    "def build_where_clause(rules: list) -> str:\n",
    "    \"\"\"Builds SQL OR-clauses from rule tuples.\"\"\"\n",
    "    parts = [f\"({tc} = '{tv}' AND {c} LIKE '{pat}')\" for c, tc, tv, pat in rules]\n",
    "    return \"(\" + \" OR \".join(parts) + \")\"\n",
    "\n",
    "def or_stats(a, b, c, d, add_halves=True):\n",
    "    \"\"\"Calculates odds ratio and 95% CI with Haldane-Anscombe correction.\"\"\"\n",
    "    if add_halves and (0 in (a, b, c, d)):\n",
    "        a, b, c, d = a + 0.5, b + 0.5, c + 0.5, d + 0.5\n",
    "    \n",
    "    if b == 0 or c == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    OR = (a * d) / (b * c)\n",
    "    logOR = math.log(OR)\n",
    "    SE = math.sqrt(1/a + 1/b + 1/c + 1/d)\n",
    "    lcl = math.exp(logOR - 1.96 * SE)\n",
    "    ucl = math.exp(logOR + 1.96 * SE)\n",
    "    \n",
    "    return OR, logOR, SE, lcl, ucl\n",
    "\n",
    "def ae_window_predicate(ae_col, idx_col, window_days):\n",
    "    \"\"\"Generates a SQL predicate for an AE occurring within a specified window.\"\"\"\n",
    "    if window_days is None:\n",
    "        return f\"{ae_col} > {idx_col}\"\n",
    "    return f\"({ae_col} > {idx_col} AND {ae_col} <= {idx_col} + INTERVAL '{int(window_days)}' DAY)\"\n",
    "\n",
    "console.print(\"[bold green]✓[/bold green] All imports and helper functions loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760339f9",
   "metadata": {},
   "source": [
    "## Step 1: Select Configuration\n",
    "\n",
    "Choose which configuration to run. You can modify the index or select by criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select configuration - modify this to test different configs\n",
    "# Option 1: Select by index\n",
    "config_index = 1  # Change this to select different configs\n",
    "\n",
    "# Option 2: Select by criteria (uncomment to use)\n",
    "# config_index = next(i for i, c in enumerate(CONFIGURATIONS) \n",
    "#                     if c.get(\"enabled\", True) and c[\"disease\"] == \"hypertension\")\n",
    "\n",
    "config = CONFIGURATIONS[config_index]\n",
    "\n",
    "# Display selected config\n",
    "title = f\"Selected Configuration: {clean_label(config['disease'])} + {clean_label(config['comorbidity'])}\"\n",
    "content = Text(no_wrap=True)\n",
    "content.append(\"  Disease (D): \", style=\"green\"); content.append(f\"{clean_label(config['disease'])}\\n\")\n",
    "content.append(\"  Comorbidity (D2): \", style=\"green\"); content.append(f\"{clean_label(config['comorbidity'])}\\n\")\n",
    "\n",
    "if config.get(\"drug_group_name\"):\n",
    "    content.append(\"  Drug Group (C): \", style=\"green\"); content.append(f\"{config['drug_group_name']}\\n\")\n",
    "    content.append(\"  Individual Drugs: \", style=\"green\"); content.append(f\"{', '.join(config['drugs'])}\\n\")\n",
    "else:\n",
    "    drug_label = \"Drug (C)\" if len(config['drugs']) == 1 else \"Drugs (C)\"\n",
    "    content.append(f\"  {drug_label}: \", style=\"green\"); content.append(f\"{', '.join(config['drugs'])}\\n\")\n",
    "\n",
    "aes = config.get(\"aes\", [])\n",
    "positive_controls = config.get(\"positive_controls\", [])\n",
    "negative_controls = config.get(\"negative_controls\", [])\n",
    "\n",
    "if aes:\n",
    "    content.append(\"  Adverse Events (E): \", style=\"green\"); content.append(f\"{', '.join(aes)}\\n\")\n",
    "if positive_controls:\n",
    "    content.append(\"  Positive Controls: \", style=\"cyan\"); content.append(f\"{', '.join(positive_controls)}\\n\")\n",
    "if negative_controls:\n",
    "    content.append(\"  Negative Controls: \", style=\"yellow\"); content.append(f\"{', '.join(negative_controls)}\\n\")\n",
    "\n",
    "console.print(Panel(content, title=title, border_style=\"cyan\", title_align=\"left\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed8759",
   "metadata": {},
   "source": [
    "## Step 2: Load Definition Files and Population AE Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shared definition files\n",
    "with console.status(\"[b]Loading shared definition files...[/b]\", spinner=\"dots\"):\n",
    "    group_files = {\n",
    "        \"base\": GROUPS_DIR / \"base.csv\",\n",
    "        \"comorbidity\": GROUPS_DIR / \"comorbidities.csv\",\n",
    "        \"drugs\": GROUPS_DIR / \"drugs.csv\",\n",
    "        \"ae\": GROUPS_DIR / \"adverse_effects.csv\",\n",
    "        \"confounders\": GROUPS_DIR / \"confounders.csv\"\n",
    "    }\n",
    "    group_dfs = {}\n",
    "    for name, path in group_files.items():\n",
    "        if path.exists():\n",
    "            group_dfs[name] = _read_clean_groups(path)\n",
    "        else:\n",
    "            if name == 'confounders':\n",
    "                console.print(f\"[yellow]NOTE: '{path.name}' not found. Regression will only adjust for age, sex, and SES.[/yellow]\")\n",
    "                group_dfs[name] = pd.DataFrame()\n",
    "            else:\n",
    "                console.print(f\"[bold red]ERROR:[/] Essential definition file not found: {path}. Exiting.\")\n",
    "                raise FileNotFoundError(f\"Essential definition file not found: {path}\")\n",
    "console.print(\"✓ Shared definition files loaded.\")\n",
    "\n",
    "# Load population AE prevalence data\n",
    "with console.status(\"[b]Loading population AE prevalence data...[/b]\", spinner=\"dots\"):\n",
    "    pop_ae_file = ROOT_DIR / \"data\" / \"codes\" / \"ae_patient_counts.csv\"\n",
    "    pop_ae_df = pd.read_csv(pop_ae_file)\n",
    "    if pop_ae_df[\"prevalence_pct\"].dropna().between(0, 1).all():\n",
    "        pop_ae_df[\"prevalence_pct\"] = pop_ae_df[\"prevalence_pct\"] * 100.0\n",
    "console.print(\"✓ Population AE prevalence data loaded.\")\n",
    "\n",
    "# Initialize database connection\n",
    "con = duckdb.connect(database=\":memory:\")\n",
    "console.print(\"✓ DuckDB connection established.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828580ea",
   "metadata": {},
   "source": [
    "## Step 3: Load and Validate Selections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(Panel(\"Step 1: Load and Validate Selections\", title_align=\"left\", border_style=\"blue\"))\n",
    "\n",
    "disease, comorbidity, drugs = config[\"disease\"], config[\"comorbidity\"], config[\"drugs\"]\n",
    "# Combine all AEs for processing\n",
    "aes = config.get(\"aes\", [])\n",
    "positive_controls = config.get(\"positive_controls\", [])\n",
    "negative_controls = config.get(\"negative_controls\", [])\n",
    "aes = aes + positive_controls + negative_controls\n",
    "\n",
    "sel_disease, sel_comorb = [disease.strip().casefold()], [comorbidity.strip().casefold()]\n",
    "sel_drugs, sel_aes = [d.strip().casefold() for d in drugs], [a.strip().casefold() for a in aes]\n",
    "sel_confounders = [c.strip().casefold() for c in config.get(\"confounders\", [])]\n",
    "\n",
    "def _rules_from(df, selected_names):\n",
    "    sub = df[df[\"name_key\"].isin(selected_names)].drop_duplicates()\n",
    "    return [(r.col, r.type_col, r.type_val, r.like_pattern) for r in sub.itertuples(index=False)]\n",
    "\n",
    "with console.status(\"[b]Loading definitions and rules...[/b]\", spinner=\"dots\"):\n",
    "    base_disease_rules = _rules_from(group_dfs[\"base\"], sel_disease)\n",
    "    comorbidity_rules = _rules_from(group_dfs[\"comorbidity\"], sel_comorb)\n",
    "    drug_codes = group_dfs[\"drugs\"][group_dfs[\"drugs\"][\"name_key\"].isin(sel_drugs)][\"atc5_code\"].dropna().unique().tolist()\n",
    "    \n",
    "    adverse_events = []\n",
    "    for ae_name, grp in group_dfs[\"ae\"][group_dfs[\"ae\"][\"name_key\"].isin(sel_aes)].groupby(\"name_key\", sort=True):\n",
    "        rules = [(r.col, r.type_col, r.type_val, r.like_pattern) for r in grp.itertuples(index=False)]\n",
    "        adverse_events.append({\"name\": grp['name'].iloc[0], \"rules\": rules})\n",
    "\n",
    "    confounder_definitions = []\n",
    "    if sel_confounders and \"confounders\" in group_dfs:\n",
    "        for conf_name, grp in group_dfs[\"confounders\"][group_dfs[\"confounders\"][\"name_key\"].isin(sel_confounders)].groupby(\"name_key\", sort=True):\n",
    "            rules = [(r.col, r.type_col, r.type_val, r.like_pattern) for r in grp.itertuples(index=False)]\n",
    "            confounder_definitions.append({\"name\": grp['name'].iloc[0], \"rules\": rules})\n",
    "\n",
    "console.print(f\"  [green]Disease rules found:[/green] {len(base_disease_rules)}\")\n",
    "console.print(f\"  [green]Comorbidity rules found:[/green] {len(comorbidity_rules)}\")\n",
    "console.print(f\"  [green]Drug ATC5 codes found:[/green] {len(drug_codes)}\")\n",
    "console.print(f\"  [green]Adverse events found:[/green] {len(adverse_events)}\")\n",
    "console.print(f\"  [green]Confounder definitions found:[/green] {len(confounder_definitions)}\")\n",
    "\n",
    "for label, obj in [(\"DISEASE\", base_disease_rules), (\"COMORBIDITY\", comorbidity_rules), (\"DRUGS\", drug_codes), (\"AEs\", adverse_events)]:\n",
    "    if not obj:\n",
    "        console.print(f\"  [bold red]ERROR:[/] No entries found for '{label}'. Check names in config and CSVs.\")\n",
    "        raise ValueError(f\"No entries found for '{label}'\")\n",
    "\n",
    "console.print(\"  [green]✓ Selections validated successfully.[/green]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f150e",
   "metadata": {},
   "source": [
    "## Step 4: Set Up Database Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(Panel(\"Step 2: Set Up Database Views\", title_align=\"left\", border_style=\"blue\"))\n",
    "\n",
    "cohort_dir = DATA_DIR / \"cohorts\" / disease\n",
    "pop_file = cohort_dir / f\"population_{disease}.parquet\"\n",
    "dx_file = cohort_dir / f\"diagnoses_{disease}.parquet\"\n",
    "med_file = cohort_dir / f\"meds_{disease}.parquet\"\n",
    "\n",
    "if not all([pop_file.exists(), dx_file.exists(), med_file.exists()]):\n",
    "    console.print(f\"  [bold red]ERROR:[/] Data files not found for disease '{disease}' in {cohort_dir}.\")\n",
    "    raise FileNotFoundError(f\"Data files not found for disease '{disease}'\")\n",
    "\n",
    "# Define save directory\n",
    "drug_slug = slugify(config.get(\"drug_group_name\") or '_'.join(drugs))\n",
    "save_dir_name = slugify(f\"{disease}-{comorbidity}-{drug_slug}\")\n",
    "save_dir = RESULTS_DIR / \"ae_prevalence\" / slugify(disease) / save_dir_name\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with console.status(\"[b]Creating database views from Parquet files...[/b]\", spinner=\"dots\"):\n",
    "    con.execute(f\"CREATE OR REPLACE VIEW dx AS SELECT patient_id, time_stamp::DATE AS diagnosis_date, TRIM(code1) AS code1, code_type1 FROM read_parquet('{dx_file.as_posix()}');\")\n",
    "    con.execute(f\"CREATE OR REPLACE VIEW meds AS SELECT patient_id, time_stamp::DATE AS rx_start_date, code1 AS atc5_code, type FROM read_parquet('{med_file.as_posix()}') WHERE type = 'Medications purchase';\")\n",
    "    latest_date = con.execute(\"SELECT MAX(diagnosis_date) FROM dx;\").fetchone()[0]\n",
    "    admin_end_date = latest_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Load population data into a Pandas DataFrame for imputation\n",
    "    pop_df = pd.read_parquet(pop_file)\n",
    "    \n",
    "    # --- Imputation of and categorization of socioeconomic_status ---\n",
    "    console.print(\"  [yellow]Categorizing and imputing socioeconomic status...[/yellow]\")\n",
    "    n_missing_before = pop_df['socioeconomic_status'].isna().sum()\n",
    "\n",
    "    # Create categorical SES levels based on population tertiles (~33% each).\n",
    "    ses_cats = pd.qcut(\n",
    "        pop_df['socioeconomic_status'],\n",
    "        q=3,\n",
    "        labels=['low', 'intermediate', 'high'],\n",
    "        duplicates='drop'\n",
    "    )\n",
    "\n",
    "    # Impute missing SES values by assigning them to the 'intermediate' category.\n",
    "    pop_df['socioeconomic_status'] = ses_cats.astype('object').fillna('intermediate')\n",
    "\n",
    "    # Ensure the column has a consistent categorical type\n",
    "    ses_order = ['low', 'intermediate', 'high']\n",
    "    pop_df['socioeconomic_status'] = pop_df['socioeconomic_status'].astype(pd.CategoricalDtype(categories=ses_order, ordered=True))\n",
    "    \n",
    "    n_imputed = n_missing_before\n",
    "    console.print(f\"  [green]Categorized SES into 3 levels and imputed {n_imputed:,} missing values to 'intermediate'.[/green]\")\n",
    "\n",
    "    # Define observation end date for the view\n",
    "    pop_df['observation_end_date'] = pd.to_datetime(pop_df['date_of_death']).fillna(pd.to_datetime(admin_end_date))\n",
    "    \n",
    "    # Register the imputed Pandas DataFrame as a temporary DuckDB table\n",
    "    con.register('pop_imputed', pop_df)\n",
    "    \n",
    "    # Create the final 'pop' view, now including sex and the imputed socioeconomic_status\n",
    "    con.execute(\"\"\"\n",
    "        CREATE OR REPLACE VIEW pop AS \n",
    "        SELECT \n",
    "            patient_id, \n",
    "            date_of_birth::DATE AS birth_date,\n",
    "            observation_end_date::DATE AS observation_end_date,\n",
    "            sex,\n",
    "            socioeconomic_status\n",
    "        FROM pop_imputed;\n",
    "    \"\"\")\n",
    "\n",
    "cohort_size = con.execute('SELECT COUNT(*) FROM pop;').fetchone()[0]\n",
    "console.print(f\"  [green]Overall cohort size for '{disease}':[/green] {cohort_size:,}\")\n",
    "\n",
    "# --- Demographic Summary ---\n",
    "console.print(Panel(\"Demographic Summary of Population\", title_align=\"left\", border_style=\"blue\"))\n",
    "\n",
    "sex_counts = pop_df['sex'].value_counts()\n",
    "ses_counts = pop_df['socioeconomic_status'].value_counts()\n",
    "\n",
    "demographics_table = Table(title=f\"Population Demographics for '{clean_label(disease)}'\")\n",
    "demographics_table.add_column(\"Statistic\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "demographics_table.add_column(\"Value\", justify=\"left\", style=\"magenta\")\n",
    "\n",
    "demographics_table.add_row(\"Total Patients\", f\"{len(pop_df):,}\")\n",
    "if 'F' in sex_counts:\n",
    "    demographics_table.add_row(\"Females\", f\"{sex_counts['F']:,} ({sex_counts['F']/len(pop_df)*100:.1f}%)\")\n",
    "if 'M' in sex_counts:\n",
    "    demographics_table.add_row(\"Males\", f\"{sex_counts['M']:,} ({sex_counts['M']/len(pop_df)*100:.1f}%)\")\n",
    "\n",
    "demographics_table.add_section()\n",
    "demographics_table.add_row(\"[bold]SES Category[/bold]\", \"\")\n",
    "if 'low' in ses_counts:\n",
    "    demographics_table.add_row(\"  Low\", f\"{ses_counts['low']:,} ({ses_counts['low']/len(pop_df)*100:.1f}%)\")\n",
    "if 'intermediate' in ses_counts:\n",
    "    demographics_table.add_row(\"  Intermediate\", f\"{ses_counts['intermediate']:,} ({ses_counts['intermediate']/len(pop_df)*100:.1f}%)\")\n",
    "if 'high' in ses_counts:\n",
    "    demographics_table.add_row(\"  High\", f\"{ses_counts['high']:,} ({ses_counts['high']/len(pop_df)*100:.1f}%)\")\n",
    "    \n",
    "console.print(demographics_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8749a0",
   "metadata": {},
   "source": [
    "## Step 5: Compute Index Dates and Define Cohorts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ba58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(Panel(\"Step 3: Compute Index Dates and Define Cohorts\", title_align=\"left\", border_style=\"blue\"))\n",
    "\n",
    "with console.status(\"[b]Identifying first diagnosis/drug dates...[/b]\", spinner=\"dots\"):\n",
    "    con.execute(f\"CREATE OR REPLACE TEMP TABLE base_disease AS SELECT patient_id, MIN(diagnosis_date) AS base_date FROM dx WHERE {build_where_clause(base_disease_rules)} GROUP BY patient_id;\")\n",
    "    con.execute(f\"CREATE OR REPLACE TEMP TABLE comorbidity AS SELECT patient_id, MIN(diagnosis_date) AS comorb_date FROM dx WHERE {build_where_clause(comorbidity_rules)} GROUP BY patient_id;\")\n",
    "    con.execute(f\"CREATE OR REPLACE TEMP TABLE drug_exposure AS SELECT patient_id, MIN(rx_start_date) AS drug_date FROM meds WHERE atc5_code IN {tuple(drug_codes)} GROUP BY patient_id;\")\n",
    "\n",
    "with console.status(\"[b]Building master patient flag table...[/b]\", spinner=\"dots\"):\n",
    "    con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TEMP TABLE patient_flags AS\n",
    "    SELECT p.patient_id,\n",
    "        CASE WHEN bd.base_date IS NOT NULL THEN 1 ELSE 0 END AS base_disease, bd.base_date,\n",
    "        CASE WHEN cd.comorb_date IS NOT NULL THEN 1 ELSE 0 END AS comorbidity, cd.comorb_date,\n",
    "        CASE WHEN de.drug_date IS NOT NULL THEN 1 ELSE 0 END AS drug, de.drug_date\n",
    "    FROM pop p\n",
    "    LEFT JOIN base_disease bd USING (patient_id) LEFT JOIN comorbidity cd USING (patient_id) LEFT JOIN drug_exposure de USING (patient_id);\n",
    "    \"\"\")\n",
    "\n",
    "with console.status(\"[b]Calculating cohort sizes...[/b]\", spinner=\"dots\"):\n",
    "    n_d, n_d2, n_c, n_d_d2, n_d_c, n_d_d2_c = con.execute(\"\"\"\n",
    "        SELECT SUM(base_disease), \n",
    "               SUM(comorbidity), \n",
    "               SUM(drug),\n",
    "               SUM(CASE WHEN base_disease = 1 AND comorbidity = 1 THEN 1 ELSE 0 END),\n",
    "               SUM(CASE WHEN base_disease = 1 AND drug = 1 THEN 1 ELSE 0 END),\n",
    "               SUM(CASE WHEN base_disease = 1 AND comorbidity = 1 AND drug = 1 THEN 1 ELSE 0 END)\n",
    "        FROM patient_flags;\n",
    "    \"\"\").fetchone()\n",
    "    con.execute(\"CREATE OR REPLACE TEMP TABLE cohort1 AS SELECT * FROM patient_flags WHERE base_disease = 1;\")\n",
    "    con.execute(\"CREATE OR REPLACE TEMP TABLE cohort2 AS SELECT * FROM patient_flags WHERE base_disease = 1 AND comorbidity = 1;\")\n",
    "    con.execute(\"CREATE OR REPLACE TEMP TABLE cohort3 AS SELECT * FROM patient_flags WHERE base_disease = 1 AND drug = 1;\")\n",
    "    con.execute(\"CREATE OR REPLACE TEMP TABLE cohort4 AS SELECT * FROM patient_flags WHERE base_disease = 1 AND comorbidity = 1 AND drug = 1;\")\n",
    "\n",
    "table = Table(title=\"Cohort Sizes\")\n",
    "table.add_column(\"Cohort Definition\", justify=\"right\", style=\"cyan\", no_wrap=True)\n",
    "table.add_column(\"Patient Count\", justify=\"right\", style=\"magenta\")\n",
    "table.add_row(\"N(D)\", f\"{n_d:,}\")\n",
    "table.add_row(\"N(D2)\", f\"{n_d2:,}\")\n",
    "table.add_row(\"N(C)\", f\"{n_c:,}\")\n",
    "table.add_row(\"N(D + D2) [c2]\", f\"{n_d_d2:,}\")\n",
    "table.add_row(\"N(D + C) [c3]\", f\"{n_d_c:,}\")\n",
    "table.add_row(\"N(D + D2 + C) [c4]\", f\"{n_d_d2_c:,}\")\n",
    "console.print(table)\n",
    "\n",
    "console.print(f\"\\n[bold]Results will be saved to:[/bold] [blue underline]{save_dir.relative_to(RESULTS_DIR)}[/blue underline]\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e35e42",
   "metadata": {},
   "source": [
    "## Step 6: Calculate Unadjusted Odds Ratios\n",
    "\n",
    "You can inspect the results in the `unadjusted_or_results` variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(Panel(\"Step 4a: Calculate Unadjusted Odds Ratios\", title_align=\"left\", border_style=\"blue\"))\n",
    "\n",
    "with console.status(\"[b]Defining analysis sets...[/b]\", spinner=\"dots\"):\n",
    "    con.execute(\"CREATE OR REPLACE TEMP TABLE analysis_set AS SELECT * FROM patient_flags WHERE base_disease = 1 AND comorbidity = 1;\")\n",
    "    con.execute(\"CREATE OR REPLACE TEMP TABLE exposed_riskset AS SELECT patient_id, GREATEST(base_date, comorb_date, drug_date) AS index_date FROM analysis_set WHERE drug = 1;\")\n",
    "    con.execute(\"CREATE OR REPLACE TEMP TABLE unexposed_riskset AS SELECT patient_id, GREATEST(base_date, comorb_date) AS index_date FROM analysis_set WHERE drug = 0;\")\n",
    "\n",
    "total_exp = con.execute(\"SELECT COUNT(*) FROM exposed_riskset;\").fetchone()[0]\n",
    "total_unexp = con.execute(\"SELECT COUNT(*) FROM unexposed_riskset;\").fetchone()[0]\n",
    "console.print(f\"  [green]Exposed starters (D+D2+C):[/green] {total_exp:,}\")\n",
    "console.print(f\"  [green]Unexposed starters (D+D2, no C):[/green] {total_unexp:,}\")\n",
    "\n",
    "if total_exp == 0 or total_unexp == 0:\n",
    "    console.print(\"  [bold yellow]WARNING:[/] Cannot calculate odds ratios with zero patients in an analysis group.\")\n",
    "    unadjusted_or_results = pd.DataFrame()\n",
    "else:\n",
    "    rows = []\n",
    "    for ae in track(adverse_events, description=\"Computing unadjusted ORs for AEs...\"):\n",
    "        ae_name, ae_slug = ae[\"name\"], slugify(ae[\"name\"])\n",
    "        ae_where = build_where_clause(ae[\"rules\"])\n",
    "        con.execute(f\"CREATE OR REPLACE TEMP TABLE ae_{ae_slug} AS SELECT patient_id, MIN(diagnosis_date) AS ae_date FROM dx WHERE {ae_where} GROUP BY patient_id;\")\n",
    "\n",
    "        for W in WINDOWS:\n",
    "            win_label = \"any_after_index\" if W is None else f\"{W}d\"\n",
    "            pred_exp = ae_window_predicate(\"a.ae_date\", \"e.index_date\", W)\n",
    "            pred_unx = ae_window_predicate(\"a.ae_date\", \"u.index_date\", W)\n",
    "\n",
    "            a = con.execute(f\"SELECT COUNT(DISTINCT e.patient_id) FROM exposed_riskset e JOIN ae_{ae_slug} a USING (patient_id) WHERE {pred_exp};\").fetchone()[0]\n",
    "            b = total_exp - a\n",
    "            c = con.execute(f\"SELECT COUNT(DISTINCT u.patient_id) FROM unexposed_riskset u JOIN ae_{ae_slug} a USING (patient_id) WHERE {pred_unx};\").fetchone()[0]\n",
    "            d = total_unexp - c\n",
    "            \n",
    "            OR, logOR, SE, lcl, ucl = or_stats(a, b, c, d)\n",
    "            \n",
    "            rows.append({\n",
    "                \"adverse_event\": clean_label(ae_name), \"window\": win_label,\n",
    "                \"a_exposed_E\": a, \"b_exposed_noE\": b, \"c_unexposed_E\": c, \"d_unexposed_noE\": d,\n",
    "                \"total_exposed\": total_exp, \"total_unexposed\": total_unexp,\n",
    "                \"odds_ratio\": OR, \"log_or\": logOR, \"se_log_or\": SE, \"ci95_low\": lcl, \"ci95_high\": ucl\n",
    "            })\n",
    "            \n",
    "    unadjusted_or_results = pd.DataFrame(rows).sort_values([\"adverse_event\", \"window\"]).reset_index(drop=True)\n",
    "\n",
    "# Display results\n",
    "if not unadjusted_or_results.empty:\n",
    "    console.print(f\"\\n[bold]Unadjusted OR Results:[/bold]\")\n",
    "    display(unadjusted_or_results)\n",
    "else:\n",
    "    console.print(\"[yellow]No unadjusted OR results to display.[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c9f65",
   "metadata": {},
   "source": [
    "## Step 7: Calculate Adjusted Odds Ratios (Confounder-Adjusted)\n",
    "\n",
    "You can inspect the results in the `adjusted_or_results` variable. This step is skipped if `run_regression` is False in the config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.get(\"run_regression\", True):\n",
    "    console.print(Panel(\"Step 4b: Calculate Confounder-Adjusted Odds Ratios\", title_align=\"left\", border_style=\"blue\"))\n",
    "    \n",
    "    with console.status(\"[b]Building base regression dataset...[/b]\", spinner=\"dots\"):\n",
    "        con.execute(\"\"\"\n",
    "            CREATE OR REPLACE TEMP TABLE regression_base AS\n",
    "            (SELECT patient_id, 1 AS exposed, GREATEST(base_date, comorb_date, drug_date) AS index_date FROM patient_flags WHERE base_disease = 1 AND comorbidity = 1 AND drug = 1)\n",
    "            UNION ALL\n",
    "            (SELECT patient_id, 0 AS exposed, GREATEST(base_date, comorb_date) AS index_date FROM patient_flags WHERE base_disease = 1 AND comorbidity = 1 AND drug = 0);\n",
    "        \"\"\")\n",
    "\n",
    "        base_query = \"\"\"\n",
    "            SELECT\n",
    "                r.patient_id, r.exposed, r.index_date, p.sex, p.socioeconomic_status,\n",
    "                DATE_DIFF('year', p.birth_date, r.index_date) AS age_at_index\n",
    "            FROM regression_base r\n",
    "            JOIN pop p ON r.patient_id = p.patient_id\n",
    "        \"\"\"\n",
    "        con.execute(f\"CREATE OR REPLACE TEMP TABLE regression_data AS ({base_query});\")\n",
    "\n",
    "    # Add specified confounders as binary flags\n",
    "    confounder_slugs = []\n",
    "    if confounder_definitions:\n",
    "        for conf in track(confounder_definitions, description=\"Adding confounder flags...\"):\n",
    "            conf_name, conf_slug = conf[\"name\"], slugify(conf[\"name\"])\n",
    "            conf_where = build_where_clause(conf[\"rules\"])\n",
    "            confounder_slugs.append(conf_slug)\n",
    "\n",
    "            con.execute(f\"CREATE OR REPLACE TEMP TABLE {conf_slug}_dates AS SELECT patient_id, MIN(diagnosis_date) as conf_date FROM dx WHERE {conf_where} GROUP BY patient_id;\")\n",
    "            con.execute(f\"\"\"\n",
    "                CREATE OR REPLACE TEMP TABLE temp_regression_data AS\n",
    "                SELECT\n",
    "                    rd.*,\n",
    "                    CASE WHEN c.conf_date IS NOT NULL AND c.conf_date < rd.index_date THEN 1 ELSE 0 END AS {conf_slug}\n",
    "                FROM regression_data rd\n",
    "                LEFT JOIN {conf_slug}_dates c ON rd.patient_id = c.patient_id;\n",
    "            \"\"\")\n",
    "            con.execute(\"DROP TABLE regression_data;\")\n",
    "            con.execute(\"ALTER TABLE temp_regression_data RENAME TO regression_data;\")\n",
    "            con.execute(f\"DROP TABLE {conf_slug}_dates;\")\n",
    "\n",
    "    model_df = con.execute(\"SELECT * FROM regression_data;\").fetchdf()\n",
    "\n",
    "    if model_df.empty:\n",
    "        console.print(\"  [bold yellow]WARNING:[/] Base data for regression is empty. Skipping analysis.\")\n",
    "        adjusted_or_results = pd.DataFrame()\n",
    "        model_summaries = []\n",
    "    else:\n",
    "        # Build the formula string before the loop\n",
    "        confounder_slugs = [slugify(c['name']) for c in confounder_definitions]\n",
    "        base_formula = \"outcome ~ exposed + age_at_index + C(sex) + C(socioeconomic_status)\"\n",
    "        confounders_str = \" + \".join(confounder_slugs)\n",
    "        formula = f\"{base_formula} + {confounders_str}\" if confounders_str else base_formula\n",
    "        \n",
    "        console.print(Panel(f\"[cyan]Using formula for all models:[/cyan]\\n{formula}\", title=\"Regression Formula\", border_style=\"yellow\"))\n",
    "\n",
    "        all_results = []\n",
    "        model_summaries = []\n",
    "\n",
    "        # Progress bar layout\n",
    "        progress_columns = [\n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            BarColumn(), MofNCompleteColumn(), TextColumn(\"•\"),\n",
    "            TimeElapsedColumn(), TextColumn(\"•\"), TimeRemainingColumn(),\n",
    "        ]\n",
    "        \n",
    "        with Progress(*progress_columns, console=console) as progress:\n",
    "            # Create a single task for the outer loop (adverse events)\n",
    "            ae_task = progress.add_task(\"[cyan]Running regressions...\", total=len(adverse_events))\n",
    "\n",
    "            for ae in adverse_events:\n",
    "                ae_name, ae_slug = ae[\"name\"], slugify(ae[\"name\"])\n",
    "                ae_where = build_where_clause(ae[\"rules\"])\n",
    "\n",
    "                # Update progress bar\n",
    "                progress.update(ae_task, description=f\"[cyan]AE: [bold]{clean_label(ae_name)}[/bold]\")\n",
    "                \n",
    "                ae_dates_df = con.execute(f\"SELECT patient_id, MIN(diagnosis_date) AS ae_date FROM dx WHERE {ae_where} GROUP BY patient_id;\").fetchdf()\n",
    "                \n",
    "                merged_df = pd.merge(model_df, ae_dates_df, on='patient_id', how='left')\n",
    "                merged_df['index_date'] = pd.to_datetime(merged_df['index_date'])\n",
    "                merged_df['ae_date'] = pd.to_datetime(merged_df['ae_date'])\n",
    "\n",
    "                for W in WINDOWS:\n",
    "                    win_label = \"any_after_index\" if W is None else f\"{W}d\"\n",
    "                    temp_df = merged_df.copy()\n",
    "                    \n",
    "                    if W is None:\n",
    "                        temp_df['outcome'] = ((temp_df['ae_date'] > temp_df['index_date'])).astype(int)\n",
    "                    else:\n",
    "                        window_days = pd.to_timedelta(W, unit='d')\n",
    "                        temp_df['outcome'] = ((temp_df['ae_date'] > temp_df['index_date']) & (temp_df['ae_date'] <= temp_df['index_date'] + window_days)).astype(int)\n",
    "\n",
    "                    if temp_df['outcome'].sum() < 5:\n",
    "                        progress.log(f\"[yellow]Skipping model for '{ae_name}' ({win_label}): Insufficient outcome events ({temp_df['outcome'].sum()}).[/yellow]\")\n",
    "                        continue\n",
    "\n",
    "                    # Build the formula string dynamically\n",
    "                    base_formula = \"outcome ~ exposed + age_at_index + C(sex) + C(socioeconomic_status)\"\n",
    "                    confounders_str = \" + \".join(confounder_slugs)\n",
    "                    formula = f\"{base_formula} + {confounders_str}\" if confounders_str else base_formula\n",
    "                    \n",
    "                    try:\n",
    "                        model_vars = ['outcome', 'exposed', 'age_at_index', 'sex', 'socioeconomic_status'] + confounder_slugs\n",
    "                        temp_df.dropna(subset=model_vars, inplace=True)\n",
    "\n",
    "                        model = smf.logit(formula, data=temp_df).fit(maxiter=100, disp=0)\n",
    "                        \n",
    "                        params = model.params\n",
    "                        conf = model.conf_int()\n",
    "                        pvalues = model.pvalues\n",
    "                        \n",
    "                        adj_or = np.exp(params.get('exposed', np.nan))\n",
    "                        ci_low = np.exp(conf.loc['exposed', 0])\n",
    "                        ci_high = np.exp(conf.loc['exposed', 1])\n",
    "                        p_value = pvalues.get('exposed', np.nan)\n",
    "                        \n",
    "                        all_results.append({\n",
    "                            \"adverse_event\": clean_label(ae_name),\n",
    "                            \"window\": win_label,\n",
    "                            \"adjusted_odds_ratio\": adj_or,\n",
    "                            \"ci95_low\": ci_low,\n",
    "                            \"ci95_high\": ci_high,\n",
    "                            \"p_value\": p_value,\n",
    "                            \"formula\": formula\n",
    "                        })\n",
    "                        \n",
    "                        summary_title = f\"Model Summary: AE={clean_label(ae_name)}, Window={win_label}, Formula: {formula}\\n\"\n",
    "                        model_summaries.append(summary_title + model.summary().as_csv())\n",
    "\n",
    "                    except Exception as e:\n",
    "                        progress.log(f\"[bold red]ERROR:[/] Could not fit regression for '{ae_name}' ({win_label}). Reason: {e}\")\n",
    "                \n",
    "                # Manually advance the progress bar after all windows for an AE are done\n",
    "                progress.advance(ae_task)\n",
    "\n",
    "        adjusted_or_results = pd.DataFrame(all_results).sort_values([\"adverse_event\", \"window\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Display results\n",
    "    if not adjusted_or_results.empty:\n",
    "        console.print(f\"\\n[bold]Adjusted OR Results:[/bold]\")\n",
    "        display(adjusted_or_results)\n",
    "    else:\n",
    "        console.print(\"[yellow]No adjusted OR results to display.[/yellow]\")\n",
    "else:\n",
    "    console.print(\"[yellow]Skipping adjusted OR calculation (run_regression=False in config).[/yellow]\")\n",
    "    adjusted_or_results = pd.DataFrame()\n",
    "    model_summaries = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f6d03c",
   "metadata": {},
   "source": [
    "## Step 8: Calculate Prevalence Statistics\n",
    "\n",
    "You can inspect the results in the `prevalence_results` variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(Panel(\"Step 5: Calculate Prevalence Statistics\", title_align=\"left\", border_style=\"blue\"))\n",
    "\n",
    "denom_c1 = con.execute(\"SELECT COUNT(*) FROM cohort1;\").fetchone()[0]\n",
    "denom_c2 = con.execute(\"SELECT COUNT(*) FROM cohort2;\").fetchone()[0]\n",
    "denom_c3 = con.execute(\"SELECT COUNT(*) FROM cohort3;\").fetchone()[0]\n",
    "denom_c4 = con.execute(\"SELECT COUNT(*) FROM cohort4;\").fetchone()[0]\n",
    "denom_total = con.execute(\"SELECT COUNT(*) FROM pop;\").fetchone()[0]\n",
    "\n",
    "rows = []\n",
    "disease_label = clean_label(config['disease'])\n",
    "comorbidity_label = clean_label(config['comorbidity'])\n",
    "\n",
    "drug_display_name = config.get(\"drug_group_name\", ', '.join([clean_label(d) for d in config['drugs']]))\n",
    "if config.get(\"drug_group_name\"):\n",
    "    drug_display_name = clean_label(drug_display_name)\n",
    "\n",
    "for ae in track(adverse_events, description=\"Computing prevalence for AEs...\"):\n",
    "    ae_name, ae_slug = ae[\"name\"], slugify(ae[\"name\"])\n",
    "    ae_label = clean_label(ae_name)\n",
    "    ae_where = build_where_clause(ae[\"rules\"])\n",
    "    con.execute(f\"CREATE OR REPLACE TEMP TABLE ae_{ae_slug} AS SELECT patient_id, MIN(diagnosis_date) AS ae_date FROM dx WHERE {ae_where} GROUP BY patient_id;\")\n",
    "\n",
    "    n_total = con.execute(f\"SELECT COUNT(*) FROM ae_{ae_slug};\").fetchone()[0]\n",
    "    # c1 = D\n",
    "    n1 = con.execute(f\"SELECT COUNT(*) FROM cohort1 c JOIN ae_{ae_slug} a USING (patient_id) WHERE a.ae_date > c.base_date;\").fetchone()[0]\n",
    "    # c2 = D + D2\n",
    "    n2 = con.execute(f\"SELECT COUNT(*) FROM cohort2 c JOIN ae_{ae_slug} a USING (patient_id) WHERE a.ae_date > GREATEST(c.base_date, c.comorb_date);\").fetchone()[0]\n",
    "    # c3 = D + C\n",
    "    n3 = con.execute(f\"SELECT COUNT(*) FROM cohort3 c JOIN ae_{ae_slug} a USING (patient_id) WHERE a.ae_date > GREATEST(c.base_date, c.drug_date);\").fetchone()[0]\n",
    "    # c4 = D + D2 + C\n",
    "    n4 = con.execute(f\"SELECT COUNT(*) FROM cohort4 c JOIN ae_{ae_slug} a USING (patient_id) WHERE a.ae_date > GREATEST(c.base_date, c.comorb_date, c.drug_date);\").fetchone()[0]\n",
    "\n",
    "    rows.extend([\n",
    "        {\"adverse_event\": ae_label, \"cohort\": \"total\", \"n_with_AE\": n_total, \"denominator\": denom_total, \"prevalence_pct\": (n_total / denom_total * 100.0) if denom_total else 0.0},\n",
    "        {\"adverse_event\": ae_label, \"cohort\": f\"{disease_label}\", \"n_with_AE\": n1, \"denominator\": denom_c1, \"prevalence_pct\": (n1 / denom_c1 * 100.0) if denom_c1 else 0.0},\n",
    "        {\"adverse_event\": ae_label, \"cohort\": f\"{disease_label} + {comorbidity_label}\", \"n_with_AE\": n2, \"denominator\": denom_c2, \"prevalence_pct\": (n2 / denom_c2 * 100.0) if denom_c2 else 0.0},\n",
    "        {\"adverse_event\": ae_label, \"cohort\": f\"{disease_label} + {drug_display_name}\", \"n_with_AE\": n3, \"denominator\": denom_c3, \"prevalence_pct\": (n3 / denom_c3 * 100.0) if denom_c3 else 0.0},\n",
    "        {\"adverse_event\": ae_label, \"cohort\": f\"{disease_label} + {comorbidity_label} + {drug_display_name}\", \"n_with_AE\": n4, \"denominator\": denom_c4, \"prevalence_pct\": (n4 / denom_c4 * 100.0) if denom_c4 else 0.0}\n",
    "    ])\n",
    "\n",
    "prevalence_results = pd.DataFrame(rows)\n",
    "\n",
    "# Display results\n",
    "if not prevalence_results.empty:\n",
    "    console.print(f\"\\n[bold]Prevalence Results:[/bold]\")\n",
    "    display(prevalence_results)\n",
    "else:\n",
    "    console.print(\"[yellow]No prevalence results to display.[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abccee23",
   "metadata": {},
   "source": [
    "## Step 9: Generate Plots\n",
    "\n",
    "This step generates bar plots for AE prevalence. The plots are saved to the results directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting helper functions from ae_prevalence.py\n",
    "def format_cohort_label(label, width=15):\n",
    "    \"\"\"Formats cohort labels for plot axes.\"\"\"\n",
    "    segs = [s for s in re.split(r\"\\s*\\+\\s*\", str(label).strip()) if s]\n",
    "    lines = []\n",
    "    n = len(segs)\n",
    "    for i, seg in enumerate(segs):\n",
    "        is_last = (i == n - 1)\n",
    "        wrap_w = width if is_last else max(1, width - 2)\n",
    "        wrapped = textwrap.wrap(seg, width=wrap_w, break_long_words=False)\n",
    "        if not is_last and wrapped:\n",
    "            wrapped[-1] += \" +\"\n",
    "        lines.extend(wrapped)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def add_value_labels(ax, bars, numerators, denominators, percentages):\n",
    "    \"\"\"Places text labels with counts and percentages above each bar.\"\"\"\n",
    "    for rect, num, den, pct in zip(bars, numerators, denominators, percentages):\n",
    "        if pd.notna(pct) and np.isfinite(pct):\n",
    "            label = f\"{int(num):,}\\nof {int(den):,}\\n({pct:.2f}%)\"\n",
    "            ax.annotate(\n",
    "                label,\n",
    "                xy=(rect.get_x() + rect.get_width() / 2, rect.get_height()),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha=\"center\", va=\"bottom\",\n",
    "                fontsize=10\n",
    "            )\n",
    "\n",
    "if not prevalence_results.empty:\n",
    "    console.print(Panel(\"Step 6: Generate and Save Plots\", title_align=\"left\", border_style=\"blue\"))\n",
    "    \n",
    "    disease_label = clean_label(config['disease'])\n",
    "    comorbidity_label = clean_label(config['comorbidity'])\n",
    "    drug_display_name = config.get(\"drug_group_name\", ', '.join([clean_label(d) for d in config['drugs']]))\n",
    "    if config.get(\"drug_group_name\"):\n",
    "        drug_display_name = clean_label(drug_display_name)\n",
    "    \n",
    "    # --- Standardize cohort names for consistent plotting ---\n",
    "    dynamic_c1 = disease_label\n",
    "    dynamic_c2 = f\"{disease_label} + {comorbidity_label}\"\n",
    "    dynamic_c3 = f\"{disease_label} + {drug_display_name}\"\n",
    "    dynamic_c4 = f\"{disease_label} + {comorbidity_label} + {drug_display_name}\"\n",
    "\n",
    "    cohort_map = {\n",
    "        \"population\": \"general population\",\n",
    "        dynamic_c1: \"disease\",\n",
    "        dynamic_c2: \"disease + comorbidity\",\n",
    "        dynamic_c3: \"disease + drug\",\n",
    "        dynamic_c4: \"disease + comorbidity + drug\",\n",
    "    }\n",
    "    \n",
    "    COHORT_ORDER = [\"general population\", \"total\", \"disease\", \"disease + drug\", \"disease + comorbidity\", \"disease + comorbidity + drug\"]\n",
    "    \n",
    "    available_AEs_pop = set(pop_ae_df[\"adverse_event\"].unique())\n",
    "    requested_AEs = set(prevalence_results[\"adverse_event\"].unique())\n",
    "    valid_AEs = requested_AEs & available_AEs_pop\n",
    "\n",
    "    missing_aes = requested_AEs - valid_AEs\n",
    "    for ae in missing_aes:\n",
    "        console.print(f\"  [bold yellow]WARNING:[/] Population prevalence data not available for '{ae}'. It will be excluded from plots.\")\n",
    "    \n",
    "    res_use = prevalence_results[prevalence_results[\"adverse_event\"].isin(valid_AEs)]\n",
    "    pop_use = pop_ae_df[pop_ae_df[\"adverse_event\"].isin(valid_AEs)]\n",
    "    \n",
    "    results_pop = pd.concat([res_use, pop_use], ignore_index=True)\n",
    "\n",
    "    results_pop[\"cohort_standard\"] = results_pop[\"cohort\"].map(cohort_map)\n",
    "    results_pop[\"cohort_standard\"] = results_pop[\"cohort_standard\"].fillna(results_pop[\"cohort\"])\n",
    "    results_pop[\"cohort_standard\"] = pd.Categorical(results_pop[\"cohort_standard\"], categories=COHORT_ORDER, ordered=True)\n",
    "    results_pop = results_pop.sort_values([\"adverse_event\", \"cohort_standard\"]).reset_index(drop=True)\n",
    "    \n",
    "    plot_dir = save_dir / \"barplots\"\n",
    "    plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plot_data = results_pop[~(results_pop[\"cohort_standard\"] == \"total\")].copy()\n",
    "    \n",
    "    bar_colors = [\"#e5e5e5\", \"#e9c46a\", \"#f4a261\", \"#f4a261\", \"#e76f51\"]\n",
    "\n",
    "    for ae, g in track(plot_data.groupby(\"adverse_event\", sort=True), description=\"Generating plots...\"):\n",
    "        g = g.sort_values(\"cohort_standard\")\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        x = np.arange(len(g))\n",
    "        \n",
    "        numerators = g[\"n_with_AE\"].values\n",
    "        denominators = g[\"denominator\"].values\n",
    "        percentages = g[\"prevalence_pct\"].astype(float).values\n",
    "        \n",
    "        bars = ax.bar(x, percentages, zorder=3, color=bar_colors, edgecolor=\"black\")\n",
    "        \n",
    "        add_value_labels(ax, bars, numerators, denominators, percentages)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([format_cohort_label(c) for c in g[\"cohort_standard\"].astype(str)], ha=\"center\")\n",
    "        ax.set_ylabel(\"Prevalence (%)\", fontsize=12)\n",
    "        ax.set_xlabel(\"Cohort\", fontsize=12)\n",
    "        \n",
    "        title_text = f\"{str(ae).lower()}\\nin {disease_label} + {comorbidity_label} + {drug_display_name}\"\n",
    "        ax.set_title(title_text, loc='left', pad=20, fontsize=12)\n",
    "        \n",
    "        ax.grid(axis='y', linestyle=\":\", linewidth=0.5, zorder=0)\n",
    "        ax.margins(y=0.25)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plot_base_name = slugify(f\"{ae}-prevalence-plot\")\n",
    "        fig.savefig(plot_dir / f\"{plot_base_name}.png\", dpi=300)\n",
    "        fig.savefig(plot_dir / f\"{plot_base_name}.pdf\")\n",
    "        plt.close(fig)\n",
    "    \n",
    "    console.print(f\"  [bold green]Saved[/bold green] barplots to {plot_dir}.\")\n",
    "else:\n",
    "    console.print(\"[yellow]Skipping plotting due to empty prevalence results.[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac16f087",
   "metadata": {},
   "source": [
    "## Step 10: Testing Area - Compute Number of Visits Per Patient\n",
    "\n",
    "This is where you can test code to compute the number of visits per patient. The database connection `con` and all intermediate tables are available for your experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Panel(\"Step 10: Compute Outpatient Visits Per Year (Window-Specific)\", title_align=\"left\", border_style=\"blue\"))\n",
    "\n",
    "# Load events file as DuckDB view (memory-efficient, no pandas)\n",
    "events_file = cohort_dir / f\"events_{disease}.parquet\"\n",
    "\n",
    "if not events_file.exists():\n",
    "    print(f\"  [bold red]ERROR:[/] Events file not found: {events_file}\")\n",
    "    raise FileNotFoundError(f\"Events file not found: {events_file}\")\n",
    "\n",
    "print(f\"  [green]Creating DuckDB view from:[/green] {events_file.name}\")\n",
    "con.execute(f\"CREATE OR REPLACE VIEW events AS SELECT * FROM read_parquet('{events_file.as_posix()}');\")\n",
    "\n",
    "# Get basic info without fetching large dataframes\n",
    "events_info = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_rows,\n",
    "        COUNT(DISTINCT patient_id) as unique_patients\n",
    "    FROM events\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"  [green]Total events:[/green] {events_info['total_rows'].iloc[0]:,}\")\n",
    "print(f\"  [green]Unique patients:[/green] {events_info['unique_patients'].iloc[0]:,}\")\n",
    "\n",
    "# Compute outpatient visits per year for each window\n",
    "# Only count visits within the follow-up window: index_date to index_date + window\n",
    "console.print(\"\\n[bold]Computing outpatient visits per year for each analysis window:[/bold]\")\n",
    "console.print(f\"  [yellow]Windows: {WINDOWS}[/yellow]\")\n",
    "console.print(\"  [yellow]Filtering for: type='visit' AND description != 'ER visit'[/yellow]\")\n",
    "console.print(\"  [yellow]Counting visits only within each window: index_date to index_date + window[/yellow]\")\n",
    "\n",
    "# Helper functions for window labels and column names\n",
    "def get_window_label(W):\n",
    "    return \"any_after_index\" if W is None else f\"{W}d\"\n",
    "\n",
    "def get_visits_col(W):\n",
    "    return f\"visits_{get_window_label(W)}\"\n",
    "\n",
    "def get_visits_per_year_col(W):\n",
    "    return f\"visits_per_year_{get_window_label(W)}\"\n",
    "\n",
    "# Build SQL query dynamically for all windows using a loop\n",
    "visits_select_parts = []\n",
    "visits_per_year_select_parts = []\n",
    "\n",
    "for W in WINDOWS:\n",
    "    win_label = get_window_label(W)\n",
    "    visits_col = get_visits_col(W)\n",
    "    visits_per_year_col = get_visits_per_year_col(W)\n",
    "    \n",
    "    if W is None:\n",
    "        # For None window, count all visits after index_date\n",
    "        visits_select_parts.append(f\"\"\"\n",
    "        -- Window {win_label}\n",
    "        COALESCE((\n",
    "            SELECT COUNT(DISTINCT e.time_stamp::DATE)\n",
    "            FROM events e\n",
    "            WHERE e.patient_id = r.patient_id\n",
    "              AND e.type = 'visit'\n",
    "              AND e.description != 'ER visit'\n",
    "              AND e.time_stamp::DATE > r.index_date\n",
    "        ), 0) AS {visits_col}\"\"\")\n",
    "        \n",
    "        # For \"any_after_index\", use full follow-up period\n",
    "        visits_per_year_select_parts.append(f\"\"\"\n",
    "        CASE WHEN follow_up_days > 0 THEN {visits_col} / (follow_up_days / 365.25) ELSE NULL END AS {visits_per_year_col}\"\"\")\n",
    "    else:\n",
    "        # For specific window, count visits within window\n",
    "        visits_select_parts.append(f\"\"\"\n",
    "        -- Window {win_label}\n",
    "        COALESCE((\n",
    "            SELECT COUNT(DISTINCT e.time_stamp::DATE)\n",
    "            FROM events e\n",
    "            WHERE e.patient_id = r.patient_id\n",
    "              AND e.type = 'visit'\n",
    "              AND e.description != 'ER visit'\n",
    "              AND e.time_stamp::DATE > r.index_date\n",
    "              AND e.time_stamp::DATE <= r.index_date + INTERVAL '{W}' DAY\n",
    "        ), 0) AS {visits_col}\"\"\")\n",
    "        \n",
    "        # Calculate visits per year: visits_W / (W / 365.25)\n",
    "        visits_per_year_select_parts.append(f\"\"\"\n",
    "        CASE WHEN {W} > 0 THEN {visits_col} / ({W}.0 / 365.25) ELSE NULL END AS {visits_per_year_col}\"\"\")\n",
    "\n",
    "# Create table with visit counts for all windows\n",
    "# Use regression_data directly - it already has patient_id and index_date for the analysis cohort\n",
    "# regression_data is created in Step 7 and contains:\n",
    "#   - patient_id, exposed, index_date, sex, socioeconomic_status, age_at_index\n",
    "#   - Plus any confounders that were added\n",
    "# We only need patient_id and index_date, so we can use regression_data directly\n",
    "# This ensures we compute visits for the exact same cohort used in regression\n",
    "console.print(\"  [yellow]Note:[/yellow] Using existing 'regression_data' table (created in Step 7)\")\n",
    "console.print(\"  [yellow]This ensures we compute visits for the exact same cohort used in regression[/yellow]\")\n",
    "\n",
    "visits_query = f\"\"\"\n",
    "    CREATE OR REPLACE TEMP TABLE outpatient_visits_per_year_by_window AS\n",
    "    WITH pop_with_end_date AS (\n",
    "        SELECT \n",
    "            rd.patient_id,\n",
    "            rd.index_date,\n",
    "            p.observation_end_date\n",
    "        FROM regression_data rd\n",
    "        JOIN pop p ON rd.patient_id = p.patient_id\n",
    "    )\n",
    "    SELECT \n",
    "        r.patient_id,\n",
    "        r.index_date,\n",
    "        p.observation_end_date,\n",
    "        DATE_DIFF('day', r.index_date, p.observation_end_date) AS follow_up_days,\n",
    "        {','.join(visits_select_parts)}\n",
    "    FROM regression_data r\n",
    "    JOIN pop_with_end_date p ON r.patient_id = p.patient_id\n",
    "\"\"\"\n",
    "\n",
    "con.execute(visits_query)\n",
    "console.print(\"  [green]✓[/green] Visit counts computed for all windows\")\n",
    "\n",
    "# Calculate visits per year for each window\n",
    "visits_per_year_query = f\"\"\"\n",
    "    CREATE OR REPLACE TEMP TABLE outpatient_visits_per_year_final AS\n",
    "    SELECT \n",
    "        patient_id,\n",
    "        index_date,\n",
    "        follow_up_days,\n",
    "        {','.join([get_visits_col(W) for W in WINDOWS])},\n",
    "        {','.join(visits_per_year_select_parts)}\n",
    "    FROM outpatient_visits_per_year_by_window\n",
    "\"\"\"\n",
    "\n",
    "con.execute(visits_per_year_query)\n",
    "console.print(\"  [green]✓[/green] Visits per year calculated for all windows\")\n",
    "\n",
    "# Show summary statistics without fetching large dataframes\n",
    "console.print(\"\\n[bold]Summary statistics (computed in DuckDB, not fetched):[/bold]\")\n",
    "for W in WINDOWS:\n",
    "    win_label = get_window_label(W)\n",
    "    col = get_visits_per_year_col(W)\n",
    "    \n",
    "    summary = con.execute(f\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as n,\n",
    "            AVG({col}) as mean,\n",
    "            PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY {col}) as median,\n",
    "            MIN({col}) as min_val,\n",
    "            MAX({col}) as max_val\n",
    "        FROM outpatient_visits_per_year_final\n",
    "        WHERE {col} IS NOT NULL\n",
    "    \"\"\").fetchdf()\n",
    "    \n",
    "    if len(summary) > 0 and summary['n'].iloc[0] > 0:\n",
    "        console.print(f\"  [cyan]Window {win_label}:[/cyan]\")\n",
    "        console.print(f\"    Patients: {summary['n'].iloc[0]:,}\")\n",
    "        console.print(f\"    Mean visits/year: {summary['mean'].iloc[0]:.2f}\")\n",
    "        console.print(f\"    Median visits/year: {summary['median'].iloc[0]:.2f}\")\n",
    "\n",
    "# List all available columns\n",
    "available_cols = [get_visits_per_year_col(W) for W in WINDOWS]\n",
    "console.print(f\"\\n[bold green]✓[/bold green] Outpatient visits per year computed for all windows!\")\n",
    "console.print(f\"  - Table 'outpatient_visits_per_year_final' contains visits per year for each window\")\n",
    "console.print(f\"  - Columns: {', '.join(available_cols)}\")\n",
    "console.print(\"  - Ready to join to regression_data for each window-specific analysis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names and sample data\n",
    "columns_info = con.execute(\"DESCRIBE SELECT * FROM events LIMIT 0;\").fetchdf()\n",
    "console.print(f\"  [green]Columns:[/green] {', '.join(columns_info['column_name'].tolist())}\")\n",
    "\n",
    "# Get a small sample to explore structure\n",
    "console.print(\"\\n[bold]Sample of events data (first 10 rows):[/bold]\")\n",
    "events_sample = con.execute(\"SELECT * FROM events LIMIT 10;\").fetchdf()\n",
    "display(events_sample)\n",
    "\n",
    "# Show all unique (type, description) combinations\n",
    "console.print(\"\\n[bold]All unique (type, description) combinations:[/bold]\")\n",
    "unique_type_desc = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        type,\n",
    "        description,\n",
    "        COUNT(*) as count\n",
    "    FROM events\n",
    "    GROUP BY type, description\n",
    "    ORDER BY type, description\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "console.print(f\"  [green]Total unique combinations:[/green] {len(unique_type_desc):,}\")\n",
    "console.print(f\"  [green]Total events:[/green] {unique_type_desc['count'].sum():,}\")\n",
    "\n",
    "# Display the unique combinations\n",
    "display(unique_type_desc)\n",
    "\n",
    "# Also show summary by type\n",
    "console.print(\"\\n[bold]Summary by type:[/bold]\")\n",
    "type_summary = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        type,\n",
    "        COUNT(DISTINCT description) as num_descriptions,\n",
    "        COUNT(*) as total_events\n",
    "    FROM events\n",
    "    GROUP BY type\n",
    "    ORDER BY type\n",
    "\"\"\").fetchdf()\n",
    "display(type_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
